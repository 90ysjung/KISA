############################################################
### DGA 패턴 분석을 통한 악성 도메인 분류기 및 딥러닝 알고리즘 성능비교(가칭)
############################################################

요약
   알려져있는 DGA 패턴을 분석해(open source) 악성 도메인 생성 후 딥러닝 기술로 학습하고,
   악성 도메인 분류기를 구현 합니다.
   bigram 과 lstm 알고리즘을 통해 도메인 분류(Black / White) 했으며,
   - 성능에 대한 평가 추가 할 것
   성능 테스트하고 그 결과를 분석 합니다.


1. 소개
   오늘날 사이버 범죄의 근원인 악성코드는 광범위한 연구 노력에도 불구하고 여전히 심각하며 감염은 계속 증가하고 있습니다.
   또한 해커들이 악성코드에 적용한 DGA는 더욱더 진화하면서 악성 도메인을 생성하고 있으며,
   그것을 극복하기 위한 대안도 지속하는 발전하는 것이 매우 중요합니다.
   따라서 악석코드로부터 감염된 좀비PC 와 제어서버를 효과적으로 차단하는 선제대응 기술을 필요로 합니다.
   본 실험에서는 악성코드 문제를 해결하기 위해 알려져있는 DGA 를 분석해 패턴을 파악하고
   그 패턴에 의해 생성된 악성 도메인을 딥러닝 기술로 학습하고 제어서버 도메인을 분류합니다.
   이는 미래의 악성 도메인 사전 예측을 의미하며 향후 악성 도메인 자동 분류기로 발전할 수 있습니다.
   또한 해당 알고리즘별 성능 및 분류 결과를 분석 합니다.


2. 관련 연구 
   - DGA
     - 정의(c&c 관계)
       악성 코드에 감염된 좀비PC 가 제어서버(c&c 서버)에 접속할때 DNS를 요청하게 되는데 해커는 악성코드에 DGA를 적용 합니다.
       (DNS는 제어 서버의 실제 주소와 웹사이트이 별칭(domain)을 연결시켜주는 서비스)
       DGA는 정해진 패턴에 의해 대량의 도메인을 생성하고 이를 제어서버에 접속하기 위한 도메인으로 사용하며,
       이때 제어서버의 주소를 계속 바꾸게 되어 DNS 행위 분석을 통해 악용당하고 있는 도메인에 대한 접근을 차단하거나 끊어버려도
       다른 도메인을 사용하게 되어 제어서버의 차단을 피하게 됩니다.

       예를 들어 제어서버의 도메인을 어제는 cnc1.com 로 사용하고, 오늘은 cnc2.com 를 사용하고,
       내일은 cnc3.com을 사용해(주기적인 변경) 오늘 제어서버 접속이 차단 되더라도 내일은 접속이 가능한 식이기
       때문에 항구적인 접속 차단이 어렵게 되는 것입니다.

   - bigram
     - 정의 (unigram / bigram / n-gram)
       유니그램 모형은 문장내 하나하나의 단어는 어떤 확률 분포에서 독립적으로 추출되었다고 가정 합니다.
       쉽게 말해 한 면마다 단어가 쓰인 거대한 주사위를 던져서, 온 단어들로 문장이 이뤄졌다고 보는 것 입니다.
       단어마다 문장내 출현 빈도를 알고 있으므로, 단어들을 이 확률에 따라 랜덤하게 생성할 수 있습니다.

       유니그램 모형의 확장 모형으로 바이그램(bigram) 모형이 있습니다.
       '바이(bi-)'는 '둘'이라는 뜻 입니다. 한 단어가 나타날 확률이 앞 단어에 영향을 받는다고 가정하는 것입니다.
       같은 방식으로 바이그램 모형을 확장해서 트라이그램(trigram) 모형을 만들 수도 있습니다.
       '트라이(tri-)'는 3이라는 뜻이므로 이번엔 한 단어가 나타날 확률이 바로 앞단어만이 아니라 그 앞단어에도 영향을 받습니다.

       유니그램, 바이그램, 트라이그램 같은 모형을 모두 합쳐서 N그램이라고 부르는데 N을 늘리면 늘릴 수록
       점점 더 말같은 소릴 하는 모형을 만들 수 있지만 N그램만으로는 완전한 문장을 쓸 수가 없습니다.
       N그램 모형은 확율로만 처리하고 의미론적인 부분을 처리하는 부분이 전혀 없기 때문에 아무리 N이 늘어나도
       구문론적인 관계를 전혀 포착하지 못하기 때문이다.

       예를 들어 "눈이 아파"라는 문장이 있다면 이 '눈'은 펄펄 내리는 눈(雪)이 아니라
       사람의 몸에 있는 눈(目)일 확률이 높다는 것 정도는 N그램 모형으로 식별 할 수 있습니다.

   - LSTM
     - 정의 (RNN 과 LSTM)
       RNN은 히든 노드가 방향을 가진 엣지로 연결돼 순환구조를 이루는(directed cycle) 인공신경망의 한 종류입니다.
       음성, 문자 등 순차적으로 등장하는 데이터 처리에 적합한 모델로 알려져 있으며,
       시계열 데이터 형태를 갖는 데이터의 패턴을 인식하는 인공신경망 입니다.
       RNN은 지금 들어온 입력 데이터와 과거에 입력 받았던 데이터를 동시에 고려하며
       마치 머릿속에 기억을 저장하고 있듯이 은닉층에 기억을 저장합니다.
       사람은 생각하고 판단하는 과정에서 과거의 기억에 의존하는데, RNN이 하는 일도 이와 비슷합니다.

       RNN의 변형인 LSTM은 오차의 그라디언트가 시간을 거슬러서 잘 흘러갈 수 있도록 도와줍니다.
       backprop하는 과정에서 오차의 값이 더 잘 유지되는데, 결과적으로 1000단계가 넘게 거슬러 올라갈 수 있습니다.
       이렇게 그라디언트가 잘 흘러간다는 것은 다시 말해 RNNs가 더 오래 전 일도 잘 기억한다는 의미입니다.
       LSTM 유닛은 여러 개의 게이트(gate)가 붙어있는 셀(cell)로 이루어져있으며 이 셀의 정보를
       새로 저장/셀의 정보를 불러오기/셀의 정보를 유지하는 기능이 있습니다(컴퓨터의 메모리 셀과 비슷합니다).
       셀은 셀에 연결된 게이트의 값을 보고 무엇을 저장할지, 언제 정보를 내보낼지, 언제 쓰고 언제 지울지를 결정합니다.
       이 게이트가 열리거나(1) 닫히는(0) 디지탈이 아니라 아날로그라는 점 주의하셔야 합니다.
       즉, 각 게이트는 0에서 1사이의 값을 가지며 게이트의 값에 비례해서 여러 가지 작동을 합니다.
       각 게이트가 갖는 값, 즉 게이트의 계수(또는 가중치, weight)는 은닉층의 값과 같은 원리로 학습됩니다.
       즉 게이트는 언제 신호를 불러올지/내보낼지/유지할지를 학습하며 이 학습과정은 출력의 오차를 이용한
       경사 하강법(gradient descent)을 사용합니다.


3. 실험
   - 실험 모형
     DGA 분류기의 처리 모형은 크게 2개의 모듈로 구성되어 있으며 다음 그림과 같습니다.

       - 모형 그림 삽입 할 것 -

     data_generator 은 데이터 수집 및 전처리하여 DGA 분석을 통해 파악된 패턴으로
     악성 도메인을 생성하고 학습용 데이터와 테스트용 데이터로 생성합니다.
     dga_classification 은 data_generator 로부터 생성된 학습용 데이터와 테스트용 데이터를
     사용하여 딥러닝 알고리즘을 적용하여 학습(Supervised learning) 및 분류합니다.
     사용한 딥러닝 알고리즘은 bigram 과 lstm 이며, 모든 소스 코드를 파이썬으로 구현 하었습니다.


   - data의 이해
     선별된 데이터에 대한 결과를 추출하기 위해서는 주제 또는 업무에 대한 높은 이해도를 필요로 하며
     기계학습 알고리즘을 적용하는 단계 이전에 수집된 데이터를 일차적으로 전처리 및 가공 하는 것이 선행되어야 합니다.

     - 데이터 수집처 설명 추가 할 것
       양성(White) 데이터를 위해 Alexa 상위 100 만 사이트를 사용했습니다.

     - DGA 패턴 분석 소스(open source) 설명 추가 할 것
       파이썬으로 구현된 몇 가지 DGA 알고리즘을 github 사이트를 참조하여 사용하였습니다.


   - 수집 및 전처리
     - 가공 및 전처리 과정 설명 추가 할 것
       DGA 분석을 통해 생성한 악성도메인을 label 하는 작업을 하여 딥러닝 학습에 만족하는 형태로 전처리 합니다.


   - train set / test set
     전처리 작업과 label 작업을 마친 테이터는 다음과 같습니다.
     건수 정보 추가할 것

       - 학습 데이터 예시 표 삽입 할 것 -
       - 테스트 데이터 예시 표 삽입  할 것 -


4. 결과 및 분석
   - 실험
   - 결과
     향후 연구를위한 제안

5. 결론
   본 실험에서 DGA 패턴 분석 및 분류해 기계 학습하고, 악성 도메인 분류기를 통해 악성 도메인 차단 한계 극복 가능성을 확인 했습니다.
   향후 DGA 분석 모델을 고도화하고, 학습에 적합한 새로운 알고리즘 테스트로 성능 고도화 가능성도 확인 했습니다. 




############################################################
### 위협정보 수집과 분석 기대 효과(가칭)
############################################################

요약
  수집 가능한 내부 또는 외부 인텔리전스에서 Threat hunting 을 통해
  데이터를 수집 하여 기계학습 통해 연관분석을 수행하고
  기대 효과를 도출 합니다.


1. 소개
   기존의 침해지표 분석 활동은 침해를 확인하는 용도 또는 사고 대응 성격이 강하였기 때문에,
   침해지표(IOC)를 분석해 공격 행위의 사전 탐지 및 예측에 한계가 있었습니다.
   본 실험에서는 Threat hunting 을 통해 수집한 데이터로 학습 데이터를 생성하고 전통적 방식의
   분석 한계를 극복하기 위해 기계학습을 사용하며 새로운 통찰을 기대합니다.


2. 관련 연구
   - 침해지표(IOC)
     정보보안에서 침해지표(IOC)란 디지털 침해사고를 분석하는데 사용되는 지표를 뜻합니다.
     사이버 범죄자가 남긴 디지털 증거를 추출해 내는 ‘디지털 포렌식’ 과정에서, 그러한 증거의 유형들을 지표화한 것입니다.
     이벤트 로그, 비정상적인 파일 시스템 기록 등 침해지표는 침해사고를 파악 및 분석하고 또 대응하는 기반으로 사용됩니다.

   - Threat hunting
     위협 사냥(Threat hunting)은 주로 보안기업 내에서 사이버 공격을 당하기 전 선제 방어 목적으로
     자신들의 네트워크에 존재하는 사이버 위협 요소를 능동적으로 탐지하고 제거하는 방식을 묘사할 때 쓰이던 명칭 입니다.
     모든 사이버 침입을 방어할 수 없다는 현실도 전제로 하고 있어 방어를 뚫고 들어온 공격들을
     완화시키는 활동을 통칭하며, 해당 데이터의 질과 분석 능력이 중요하고, 해당 툴을 다룰 줄 아는 사람이 필요합니다.
     즉 하나의 대세 기술이 있는 것 보다는 각자가 여러 가지 기술과 경험을 필요로 합니다.

   - 기계 학습(Text mining)
     - Apriori
       빈발 패턴 마이닝은 주어진 데이터 집합에서 재귀 관계(recurring relationships)를 찾습니다.
       빈발 항목집합 마이닝의 전형적인 예는 장바구니분석(market basket analysis)입니다.
       예를 들어, "고객이 우유를 샀다고 한다면, 그 쇼핑에서 빵을 함께 살 가능성은 얼마나 되겠는가?"
       이 질문에 답하기 위해 상점의 고객 트랜잭션에 관한 데이터에 대해 장바구니 분석을 수행해서
       상점에서 제공되는 상품의 집합으로 이루어진 세계가 있다 가정하고, 각 상품들은 상품의 존재 유무를 표현하는 이진(boolean/binary)변수를
       갖는다 가정 합니다. 이 변수들에 할당된 값으로 구성된 이진벡터(boolean/binary vector)로 표현할 수 있습니다.

       지지도(support)와 신뢰도(confidence)는 규칙의 흥미도를 측정하는 두가지 기준입니다.
       지지도가 낮은 연관규칙은 여러 트랜잭션에 적용되지 않는 규칙이어서 우연히 발생할 수 있는 규칙 또는 흥미가 없는 규칙일 가능성이 많습니다.
       따라서 최소 지지도 임계값(minimum support threshold)을 정하여 그 이하의 규칙은 버립니다.
       지지도는 좋은 규칙을 찾거나 흥미없는 규칙을 버릴 때의 기준으로 사용됩니다.

       반면에 신뢰도는 연관규칙의 신뢰성에 대한 측도 입니다.
       주어진 연관규칙 X⇒Y가 있을 때, 신뢰도가 높을수록 항목 X를 포함하는 트랜잭션은 항목 Y도 포함할 가능성이 많게 됩니다.

       최소지지도를 min_sup, 최소신뢰도를 min_conf라 할떄, 연관규칙을 탐색하는 일반적인 원칙은
       최소지지도보다 크면서 동시에 최소신뢰도보다 큰 연관규칙, 즉 강한(strong)규칙을 찾는 것입니다.

     - TF-IDF
       TF-IDF(Term Frequency - Inverse Document Frequency)는 정보 검색과 텍스트 마이닝에서 이용하는 가중치로,
       여러 문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치입니다.
       문서의 핵심어를 추출하거나, 검색 엔진에서 검색 결과의 순위를 결정하거나, 문서들 사이의 비슷한 정도를 구하는 등의 용도로 사용할 수 있습니다.
       TF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값으로,
       이 값이 높을수록 문서에서 중요하다고 생각할 수 있습니다. 하지만 단어 자체가 문서군 내에서 자주 사용되는 경우,
       이것은 그 단어가 흔하게 등장한다는 것을 의미 합니다. 이것을 DF(문서 빈도, document frequency)라고 하며,
       이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 합니다. TF-IDF는 TF와 IDF를 곱한 값 입니다.

       IDF 값은 문서군의 성격에 따라 결정 됩니다. 예를 들어 '원자'라는 낱말은 일반적인 문서들 사이에서는 잘 나오지 않기 때문에
       IDF 값이 높아지고 문서의 핵심어가 될 수 있지만, 원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 각 문서들을
       세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.



3. 데이터
   - 수집 및 전처리
     수집된 데이터는 최초에 각 알고리즘에 입력되는 변수들을 추출하는 과정이 실제로 전체과정
     (수집, 데이터준비, 알고리즘적용, 결과추출, 결과분석) 에서 70% 이상의 시간과 노력이 소모됩니다.
     본 실험에서는 내부 데이터의 워너크라이 관련 IOC 값을 기반으로, 외부 테이터 상에서 내부 데이터 IOC 값 검색 결과를 기반으로
     데이터를 수집하여, 기계학습에 맞는 형태로 가공한 후 Train set 및 Test set 을 생성 하였습니다.

   - 내부 + 외부 데이터
     C-TAS(내부 데이터) 에서 워너크라이 관련 IOC 를 csv 형태로 생성 하였습니다.
     또한 상용 인텔리전스인 Aloalto Autofocuss(외부 데이터)통해 워너크라이 관련 IOC 를 수집하고 그와 관련된
     나머지 데이터를 export 하였으며, 로컬로 내려진 두 파일을 merge 합니다.
     본 실험에서는 수동으로 200건의 데이터를 생성하여 실험을 진행 하였습니다.
     그리고 자동화(API 연동)가 이루어져야 합니다.

       - 완성형 데이터 표 삽입한다.(sample_300_ysjung.scv)


4. 기대효과
     - 실험 데이터에서 해당 악성코드와 관련있는 Autofoucs 데이터중 Tag 값과 IP값을 대상으로
       IP를 C class 대역으로 전처리 하고 IP들간 빈발 패턴을 찾기위해 연관분석을 하였고,
       Apriori 알고리즘을 적용한 코드를 파이썬으로 구현하여 실행 했습니다.
       예를 들어 특정 코드의 해시 값이 192.168.100.10, 192.168.100.11 과 같은 IP에 어떤 이벤트가 있었다 가정하면,
       해당 해시와 IP가 빈발 패턴으로 잡힐 것입니다. 즉 192.168.100 대역의 나머지 IP들도 의심해 볼 수 있으며,
       이와 관련 새로운 비즈니스로 활용 가능할 것입니다.
       또한 이런 정보는 Autofoucs 상에서는 알려주지 않는 내용입니다.

     - 실험 결과
       실험 데이터 200건의 해시, Tags, IPs 을 대상으로 한
       연관분석에서 악성코드 해시 값과 IP들 간 빈발 패턴을 추출 하였습니다.

       - 결과 표 삽입한다.

       '''
       강한 빈발 패턴으로는 블라블라.....
       이런 이유는 블라블라...
       '''

5. 결론
   본 실험에서 Threat hunting 을 통해 내부 데이터 IOC와 외부 데이터 IOC를 수집하고,
   기계학습을 통한 연관분석 또는 TF-IDF 수행으로 기존의 통계기반 분석 패턴과 다른 의미 있는 결과 도출
   가능성을 확인하는 실험을 했습니다.

   '''
   빈발 패턴으로 블라블라 결과를 얻었으며,
   이는 블라블라 의미 입니다.
   '''

   향후 새로운 ICO 연구(ICO 변수간 상관관계), 상용 인텔리전스 활용 범위 확대로 다른 변수들 간 빈발 패턴을
   탐색한다면 좀 더 의미있는 결과를 도출 할 수 있습니다.
   또한 이 결과를 기반으로 supervised learning 을 시도하여 새로운 통찰을 기대 해 볼 수 있을 것입니다.



############################################################

