############################################################
### DGA 패턴 분석을 통한 악성 도메인 분류기 및 딥러닝 알고리즘 성능비교(가칭)
############################################################

요약
   알려져있는 DGA 패턴을 분석해(open source) 악성 도메인을 생성 후 딥러닝 기술로 학습하고,
   악성 도메인 분류기를 구현 합니다.
   bigram 과 lstm 알고리즘을 통해 도메인 분류(Black / White) 했으며,
   - 성능에 대한 평가 추가 할 것
   성능 테스트하고 그 결과를 분석 합니다.


1. 소개
   오늘날 사이버 범죄의 근원인 악성코드는 광범위한 연구 노력에도 불구하고 여전히 심각하며 감염은 계속 증가하고 있습니다.
   또한 해커들이 악성코드에 적용한 DGA는 더욱더 진화하면서 악성 도메인을 생성하고 있으며,
   그것을 극복하기 위한 대안도 지속하는 발전하는 것이 매우 중요합니다.
   따라서 악석코드로부터 감염된 좀비PC 와 제어서버를 효과적으로 차단하는 선제대응 기술을 필요로 합니다.
   본 실험에서는 악성코드 문제를 해결하기 위해 알려져있는 DGA 를 분석해 패턴을 파악하고
   그 패턴에 의해 생성된 악성 도메인을 딥러닝 기술로 학습하고 제어서버 도메인을 분류합니다.
   이는 미래의 악성 도메인 사전 예측을 의미하며 향후 악성 도메인 자동 분류기로 발전할 수 있습니다.
   또한 해당 알고리즘별 성능 및 분류 결과를 분석 합니다.


2. 관련 연구 
   - DGA
     - 정의(c&c 관계)
       악성 코드에 감염된 좀비PC 가 제어서버(c&c 서버)에 접속할때 DNS를 요청하게 되는데 해커는 악성코드에 DGA를 적용 합니다.
       (DNS는 제어 서버의 실제 주소와 웹사이트이 별칭(domain)을 연결시켜주는 서비스)
       DGA는 정해진 패턴에 의해 대량의 도메인을 생성하고 이를 제어서버에 접속하기 위한 도메인으로 사용하며,
       이때 제어서버의 주소를 계속 바꾸게 되어 DNS 행위 분석을 통해 악용당하고 있는 도메인에 대한 접근을 차단하거나 끊어버려도
       다른 도메인을 사용하게 되어 제어서버의 차단을 피하게 됩니다.

       예를 들어 제어서버의 도메인을 어제는 cnc1.com 로 사용하고, 오늘은 cnc2.com 를 사용하고,
       내일은 cnc3.com을 사용해(주기적인 변경) 오늘 제어서버 접속이 차단 되더라도 내일은 접속이 가능한 식이기
       때문에 항구적인 접속 차단이 어렵게 되는 것입니다.

   - bigram
     - 정의 (unigram / bigram / n-gram)
       유니그램 모형은 문장내 하나하나의 단어는 어떤 확률 분포에서 독립적으로 추출되었다고 가정 합니다.
       쉽게 말해 한 면마다 단어가 쓰인 거대한 주사위를 던져서, 온 단어들로 문장이 이뤄졌다고 보는 것 입니다.
       단어마다 문장내 출현 빈도를 알고 있으므로, 단어들을 이 확률에 따라 랜덤하게 생성할 수 있습니다.

       유니그램 모형의 확장 모형으로 바이그램(bigram) 모형이 있습니다.
       '바이(bi-)'는 '둘'이라는 뜻 입니다. 한 단어가 나타날 확률이 앞 단어에 영향을 받는다고 가정하는 것입니다.
       같은 방식으로 바이그램 모형을 확장해서 트라이그램(trigram) 모형을 만들 수도 있습니다.
       '트라이(tri-)'는 3이라는 뜻이므로 이번엔 한 단어가 나타날 확률이 바로 앞단어만이 아니라 그 앞단어에도 영향을 받습니다.

       유니그램, 바이그램, 트라이그램 같은 모형을 모두 합쳐서 N그램이라고 부르는데 N을 늘리면 늘릴 수록
       점점 더 말같은 소릴 하는 모형을 만들 수 있지만 N그램만으로는 완전한 문장을 쓸 수가 없습니다.
       N그램 모형은 확율로만 처리하고 의미론적인 부분을 처리하는 부분이 전혀 없기 때문에 아무리 N이 늘어나도
       구문론적인 관계를 전혀 포착하지 못하기 때문이다.

       예를 들어 "눈이 아파"라는 문장이 있다면 이 '눈'은 펄펄 내리는 눈(雪)이 아니라
       사람의 몸에 있는 눈(目)일 확률이 높다는 것 정도는 N그램 모형으로 식별 할 수 있습니다.

   - LSTM
     - 정의 (RNN 과 LSTM)
       RNN은 히든 노드가 방향을 가진 엣지로 연결돼 순환구조를 이루는(directed cycle) 인공신경망의 한 종류입니다.
       음성, 문자 등 순차적으로 등장하는 데이터 처리에 적합한 모델로 알려져 있으며,
       시계열 데이터 형태를 갖는 데이터의 패턴을 인식하는 인공신경망 입니다.
       RNN은 지금 들어온 입력 데이터와 과거에 입력 받았던 데이터를 동시에 고려하며
       마치 머릿속에 기억을 저장하고 있듯이 은닉층에 기억을 저장합니다.
       사람은 생각하고 판단하는 과정에서 과거의 기억에 의존하는데, RNN이 하는 일도 이와 비슷합니다.

       RNN의 변형인 LSTM은 오차의 그라디언트가 시간을 거슬러서 잘 흘러갈 수 있도록 도와줍니다.
       backprop하는 과정에서 오차의 값이 더 잘 유지되는데, 결과적으로 1000단계가 넘게 거슬러 올라갈 수 있습니다.
       이렇게 그라디언트가 잘 흘러간다는 것은 다시 말해 RNNs가 더 오래 전 일도 잘 기억한다는 의미입니다.
       LSTM 유닛은 여러 개의 게이트(gate)가 붙어있는 셀(cell)로 이루어져있으며 이 셀의 정보를
       새로 저장/셀의 정보를 불러오기/셀의 정보를 유지하는 기능이 있습니다(컴퓨터의 메모리 셀과 비슷합니다).
       셀은 셀에 연결된 게이트의 값을 보고 무엇을 저장할지, 언제 정보를 내보낼지, 언제 쓰고 언제 지울지를 결정합니다.
       이 게이트가 열리거나(1) 닫히는(0) 디지탈이 아니라 아날로그라는 점 주의하셔야 합니다.
       즉, 각 게이트는 0에서 1사이의 값을 가지며 게이트의 값에 비례해서 여러 가지 작동을 합니다.
       각 게이트가 갖는 값, 즉 게이트의 계수(또는 가중치, weight)는 은닉층의 값과 같은 원리로 학습됩니다.
       즉 게이트는 언제 신호를 불러올지/내보낼지/유지할지를 학습하며 이 학습과정은 출력의 오차를 이용한
       경사 하강법(gradient descent)을 사용합니다.


3. 실험
   - 실험 모형
     DGA 분류기의 처리 모형은 크게 2개의 모듈로 구성되어 있으며 다음 그림과 같습니다.

       - 모형 그림 삽입 할 것 -

     data_generator 은 데이터 수집 및 전처리하여 DGA 분석을 통해 파악된 패턴으로
     악성 도메인을 생성하고 학습용 데이터와 테스트용 데이터로 생성합니다.
     dga_classification 은 data_generator 로부터 생성된 학습용 데이터와 테스트용 데이터를
     사용하여 딥러닝 알고리즘을 적용하여 학습(Supervised learning) 및 분류합니다.
     사용한 딥러닝 알고리즘은 bigram 과 lstm 이며, 모든 소스 코드를 파이썬으로 구현 하었습니다.


   - data의 이해
     선별된 데이터에 대한 결과를 추출하기 위해서는 주제 또는 업무에 대한 높은 이해도를 필요로 하며
     기계학습 알고리즘을 적용하는 단계 이전에 수집된 데이터를 일차적으로 전처리 및 가공 하는 것이 선행되어야 합니다.

     - 데이터 수집처 설명 추가 할 것
       양성(White) 데이터를 위해 Alexa 상위 100 만 사이트를 사용했습니다.

     - DGA 패턴 분석 소스(open source) 설명 추가 할 것
       파이썬으로 구현된 몇 가지 DGA 알고리즘을 github 사이트를 참조하여 사용하였습니다.


   - 수집 및 전처리
     - 가공 및 전처리 과정 설명 추가 할 것
       DGA 분석을 통해 생성한 악성도메인을 label 하는 작업을 하여 딥러닝 학습에 만족하는 형태로 전처리 합니다.


   - train set / test set
     전처리 작업과 label 작업을 마친 테이터는 다음과 같습니다.
     건수 정보 추가할 것

       - 학습 데이터 예시 표 삽입 할 것 -
       - 테스트 데이터 예시 표 삽입  할 것 -


4. 결과 및 분석
   - 실험
   - 결과
     향후 연구를위한 제안

5. 결론



############################################################
### 위협정보 수집과 분석 기대 효과(가칭)
############################################################

요약
  수집 가능한 내부 또는 외부 데이터에 Threat hunting 을 통해 
  데이터 수집 하여 기계학습 통해 연관분석을 수행하고
  기대 효과를 도출 합니다.


1. 소개
   기존의 침해지표 분석 활동은 침해를 확인하는 용도 또는 사고 대응 성격이 강하였기 때문에, 
   침해지표(IOC)를 분석해 공격 행위의 사전 탐지 및 예측에 한계가 있었습니다.
   본 실험에서는 전통적 방식의 분석 한계를 극복하기 위해
   기계학습을 사용하며 새로운 통찰을 기대합니다.


2. 관련 연구 
   - 침해지표(IOC) 
     정보보안에서 IOC 또는 침해지표란 디지털 침해사고를 분석하는데 사용되는 지표를 뜻합니다. 
     사이버 범죄자가 남긴 디지털 증거를 추출해 내는 ‘디지털 포렌식’ 과정에서, 그러한 증거의 유형들을 지표화한 것입니다. 
     이벤트 로그, 비정상적인 파일 시스템 기록 등 침해지표는 침해사고를 파악 및 분석하고 또 대응하는 기반으로 사용됩니다.
     
   - Threat hunting
   - 기계 학습 - Apriori
            - TF-IDF

3. 데이터
   - 수집 및 전처리
     수집된 데이터는 최초에 각 알고리즘에 입력되는 변수들을 추출하는 과정이 실제로 전체과정
     (수집, 데이터준비, 알고리즘적용, 결과추출, 결과분석) 에서 70% 이상의 시간과 노력이 소모됩니다.
     본 실험에서는 내부 데이터의 워너크라이 관련 IOC 값을 기반으로, 외부 테이터 상에서 내부 데이터 IOC 값 검색 결과를 기반으로
     데이터를 수집하여, 기계학습에 맞는 형태로 가공한 후 Train set 및 Test set 을 생성 하였습니다.
      
   - 내부 + 외부 데이터
     C-TAS(내부 데이터) 에서 워너크라이 관련 IOC 를 csv 형태로 생성 하였습니다.
     또한 상용 인텔리전스인 Aloalto Autofocuss(외부 데이터)통해 워너크라이 관련 IOC 를 수집하고 그와 관련된 
     나머지 데이터를 export 하였으며, 로컬로 내려진 두 파일을 merge 합니다.
     본 실험에서는 수동으로 생성하였지만 향후 자동화(API 연동)가 이루어져야 합니다.

       - 완성형 데이터 그림을 삽입한다.


4. 기대효과
   - 실험 모형
   - 연관 분석 기대효과
   - TF-IDF 기대효과


5. 결론



############################################################
